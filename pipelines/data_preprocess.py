import os, json, re, zipfile
from pathlib import Path
from config import RAW_DIR, CLEANED_DIR, ensure_dirs

# zip íŒŒì¼ëª…ì— í¬í•¨ëœ í‚¤ì›Œë“œë¡œ ì¹´í…Œê³ ë¦¬ ìë™ íŒë³„
CATEGORY_KEYWORDS = {
    "íŒê²°ë¬¸": ["íŒê²°ë¬¸"],
    "ê²°ì •ë¡€": ["ê²°ì •ë¡€"],
    "í•´ì„ë¡€": ["í•´ì„ë¡€"],
    "ë²•ë ¹":   ["ë²•ë ¹"],
}

# ì´ë¯¸ í´ë”/íŒŒì¼ì´ ìˆìœ¼ë©´ ë®ì–´ì“¸ì§€ ì—¬ë¶€ (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´)
FORCE_UNZIP = os.getenv("FORCE_UNZIP", "0") == "1"

def _detect_category(name: str) -> str:
    n = name.lower()
    for cat, kws in CATEGORY_KEYWORDS.items():
        for kw in kws:
            if kw.lower() in n:
                return cat
    return "ê¸°íƒ€"

def _normalize_zip_filenames():
    """
    í™•ì¥ì ì• ê³µë°± ê°™ì€ ì´ìƒí•œ zip ì´ë¦„ ì •ë¦¬:
      'VS_ê²°ì •ë¡€ .zip' -> 'VS_ê²°ì •ë¡€.zip'
    """
    for z in RAW_DIR.glob("*.zip"):
        fixed = RAW_DIR / z.name.replace(" .zip", ".zip")
        if fixed != z:
            try:
                z.rename(fixed)
            except Exception:
                pass

def _auto_unzip_grouped():
    """
    data/raw/*.zip â†’ zip ì´ë¦„ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ íŒë³„ í›„
    data/raw/<ì¹´í…Œê³ ë¦¬>/ ë¡œ ìë™ í•´ì œ.
    ì´ë¯¸ ëŒ€ìƒ í´ë”ì— ë‚´ìš©ë¬¼ì´ ìˆìœ¼ë©´ ê¸°ë³¸ì€ ìŠ¤í‚µ(FORCE_UNZIP=1ì´ë©´ ë®ì–´ì”€).
    """
    _normalize_zip_filenames()

    count = 0
    for z in sorted(RAW_DIR.glob("*.zip")):
        base = z.stem
        cat = _detect_category(base)
        out_dir = RAW_DIR / cat
        out_dir.mkdir(parents=True, exist_ok=True)

        # ì´ë¯¸ í’€ë ¤ ìˆìœ¼ë©´ ìŠ¤í‚µ(ê°•ì œ ëª¨ë“œ ì œì™¸)
        if not FORCE_UNZIP and any(out_dir.iterdir()):
            # ì¹´í…Œê³ ë¦¬ í´ë” ì•ˆì— íŒŒì¼ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ìŠ¤í‚µ
            continue

        try:
            with zipfile.ZipFile(z, "r") as zip_ref:
                zip_ref.extractall(out_dir)
            print(f"âœ… unzip: {z.name} -> {out_dir}")
            count += 1
        except Exception as e:
            print(f"[warn] unzip ì‹¤íŒ¨: {z.name} ({e})")
    if count == 0:
        print("[info] ìë™ í•´ì œ ëŒ€ìƒ zip ì—†ìŒ ë˜ëŠ” ì´ë¯¸ í•´ì œë¨.")

def _clean_text(s: str) -> str:
    s = s.replace("\r", "")
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()

def _extract_text_from_any(path: Path) -> str:
    # í…ìŠ¤íŠ¸/ë§ˆí¬ë‹¤ìš´/JSON/CSV ë‹¨ìˆœí™” ì¶”ì¶œ
    if path.suffix.lower() in [".txt", ".md"]:
        return path.read_text(encoding="utf-8", errors="ignore")
    elif path.suffix.lower() in [".json", ".csv"]:
        try:
            return json.dumps(
                json.loads(path.read_text(encoding="utf-8", errors="ignore")),
                ensure_ascii=False, indent=2
            )
        except Exception:
            return path.read_text(encoding="utf-8", errors="ignore")
    else:
        # ê¸°íƒ€ í™•ì¥ìëŠ” ì¼ë‹¨ í…ìŠ¤íŠ¸ë¡œ ì‹œë„
        return path.read_text(encoding="utf-8", errors="ignore")

def run():
    ensure_dirs()

    # 0) ZIP ìë™ í•´ì œ (ì¹´í…Œê³ ë¦¬ ë§¤í•‘)
    _auto_unzip_grouped()

    # 1) ì¹´í…Œê³ ë¦¬ ë””ë ‰í„°ë¦¬ ìŠ¤ìº”
    cats = [p for p in RAW_DIR.iterdir() if p.is_dir()]
    if not cats:
        print(f"[warn] {RAW_DIR} ì•„ë˜ì— ì¹´í…Œê³ ë¦¬ í´ë”ë¥¼ ë§Œë“¤ì–´ ì›ë³¸ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        return

    # 2) íŒŒì¼ë³„ ì •ì œ í…ìŠ¤íŠ¸ ìƒì„± â†’ data/cleaned/<ì¹´í…Œê³ ë¦¬>/*.txt
    for cat_dir in cats:
        out_dir = CLEANED_DIR / cat_dir.name
        out_dir.mkdir(parents=True, exist_ok=True)
        for fp in cat_dir.rglob("*"):
            if not fp.is_file():
                continue
            try:
                txt = _extract_text_from_any(fp)
                (out_dir / f"{fp.stem}.txt").write_text(_clean_text(txt), encoding="utf-8")
            except Exception as e:
                print("[skip]", fp, e)

    print("âœ… cleaned ìƒì„±:", CLEANED_DIR)

if __name__ == "__main__":
    print("ğŸ“‚ data_preprocess start")
    run()

